<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title> Describing Effects </title>
    <meta charset="utf-8" />
    <meta name="author" content="Monica Truelove-Hill" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# <b> Describing Effects </b>
]
.subtitle[
## Inferential Statistics in Applied Psychology<br>
]
.author[
### Monica Truelove-Hill
]
.institute[
### Department of Clinical Psychology<br>The University of Edinburgh
]

---








## This Week's Key Topics

+ Effect Sizes

+ Standard Error

+ Confidence Intervals 

+ Power

---
## Recap from Last Week

+ When we run a statistical test, we compare our results against the null distribution, which is the probability of the results, given the null hypothesis is true.

+ If the probability of our outcome (the `\(p\)`-value) is less than `\(\alpha\)`, it means the outcome falls into the range that we've designated as extreme.

+ Because it's really unlikely that this outcome would occur if the null hypothesis were true, we consider this sufficient evidence against the null hypothesis, and we reject it.

---
## Effect Size

+ On it's own, a `\(p\)`-value is not sufficient. 

.pull-left[.center[
![](Week02_DescribingEffects_lecture_files/figure-html/unnamed-chunk-2-1.svg)&lt;!-- --&gt;
]]

.pull-right[.center[
![](Week02_DescribingEffects_lecture_files/figure-html/unnamed-chunk-3-1.svg)&lt;!-- --&gt;
]]

---
count: false

## Effect Size

+ On it's own, a `\(p\)`-value is not sufficient. 

.pull-left[.center[
![](Week02_DescribingEffects_lecture_files/figure-html/unnamed-chunk-4-1.svg)&lt;!-- --&gt;

** `\(p\)` = .015**
]]


.pull-right[.center[
![](Week02_DescribingEffects_lecture_files/figure-html/unnamed-chunk-5-1.svg)&lt;!-- --&gt;

** `\(p\)` = .015**
]]

---
## Effect Size

+ The **effect size** reflects the magnitude of the difference between the null value and the true population value.

+ Unlike a `\(p\)`-value, which only tells you the *likelihood* that an effect or relationship exists, the effect size tells you *how strong it is*.

--

.pull-left.center[

![](Week02_DescribingEffects_lecture_files/figure-html/unnamed-chunk-6-1.svg)&lt;!-- --&gt;

]

.pull-right.center[

![](Week02_DescribingEffects_lecture_files/figure-html/unnamed-chunk-7-1.svg)&lt;!-- --&gt;

]



---
## Effect Size

+ `\(p\)`-value - is the effect significant?

+ effect size - is the effect meaningful?

+ **Both** should be reported

--

+ Many measures of effect size exist (e.g., `\(d\)`, `\(\eta^2\)`, `\(r\)`)

+ Usually, effect sizes are standardised rather than representing the raw difference between values

  + This means that comparisons can be made across different variables

???

Think about practical significance - a pharmaceutical company tests the effect of their new vitamin and finds that it significantly decreases the amount of time someone is sick over the course of a year. SIGNIFICANCE! But wait...it only decreases the amount of sick days by a single day. EFFECT SIZE. Do they really want to spend an immense amount of money for a single day's improvement?

---
## Drawing Conclusions

Given `\(\alpha\)` = .05, consider the following results:

.pull-left[

1. `\(p\)` &lt; .001, effect size = large

2. `\(p\)` = .341, effect size = large

3. `\(p\)` = .002, effect size = small

4. `\(p\)` = .512, effect size = small

]

--

.pull-right[

+ Is the result **significant?**

+ Is it **meaningful?**

+ What should be done?

]

---
class: center, inverse, middle

## Questions?

---
## Confidence Intervals

+ Remember, we don't actually know the population parameter; we're trying to estimate this with sample data.

+ A **confidence interval** defines a plausible range of values for our population parameter. 

+ The wider the interval, the more confident that we can be that the interval captures our true value.

--

&gt; How many of you are confident that I'm exactly 35 years old?

--

&gt; How many of you are confident that I'm between 32 &amp; 39 years old?

--

&gt; How many of you are confident that I'm between 25 &amp; 46 years old?


---
## Confidence Intervals

+ Remember, we don't actually know the population parameter; we're trying to estimate this with sample data.

+ A **confidence interval** defines a plausible range of values for our population parameter. 

+ The wider the interval, the more confident that we can be that the interval captures our true value.

--

+ To estimate the confidence interval, we need:

  + To define a confidence level
  + The standard error

---

## Confidence Level

+ The **confidence level** refers to the percentage of times confidence intervals would be expected to contain the true population parameter across repeated samples.

+ The typical confidence level used is **95%**

+ So, if we were to take 100 samples and calculate a 95% CI on each of them, ~95 of those intervals would contain the true population parameter.


???

+ What are we 95% confident in?

  + We are 95% confident that our interval contains the true population mean.
  
  + The 95% probability comes from the long-run frequencies of our intervals.

---
## Standard Error

+ The average deviation from the mean *within* our sample is the **standard deviation**

+ Now imagine multiple samples are taken, and the sample means are plotted each time:


--

.center[
![](Week02_DescribingEffects_lecture_files/figure-html/unnamed-chunk-8-1.svg)&lt;!-- --&gt;
]

---
count: false

## Standard Error

+ The average deviation from the mean *within* our sample is the **standard deviation**

+ Now imagine multiple samples are taken, and the sample means are plotted each time:

.center[
![](Week02_DescribingEffects_lecture_files/figure-html/unnamed-chunk-9-1.svg)&lt;!-- --&gt;
]

---
count: false

## Standard Error

+ The average deviation from the mean *within* our sample is the **standard deviation**

+ Now imagine multiple samples are taken, and the sample means are plotted each time:

.center[
![](Week02_DescribingEffects_lecture_files/figure-html/unnamed-chunk-10-1.svg)&lt;!-- --&gt;
]

---
count: false

## Standard Error

+ The average deviation from the mean *within* our sample is the **standard deviation**

+ Now imagine multiple samples are taken, and the sample means are plotted each time:

.center[
![](Week02_DescribingEffects_lecture_files/figure-html/unnamed-chunk-11-1.svg)&lt;!-- --&gt;
]

---
count: false

## Standard Error

+ The average deviation from the mean *within* our sample is the **standard deviation**

+ Now imagine multiple samples are taken, and the sample means are plotted each time:

.center[
![](Week02_DescribingEffects_lecture_files/figure-html/unnamed-chunk-12-1.svg)&lt;!-- --&gt;
]

---
count: false

## Standard Error

+ The average deviation from the mean *within* our sample is the **standard deviation**

+ Now imagine multiple samples are taken, and the sample means are plotted each time:

.center[
![](Week02_DescribingEffects_lecture_files/figure-html/unnamed-chunk-13-1.svg)&lt;!-- --&gt;
]

---
count: false

## Standard Error

+ The average deviation from the mean *within* our sample is the **standard deviation**

+ Now imagine multiple samples are taken, and the sample means are plotted each time:

.center[
![](Week02_DescribingEffects_lecture_files/figure-html/unnamed-chunk-14-1.svg)&lt;!-- --&gt;
]

+ The average deviation from the mean of the means *between* samples is the **standard error**

---
## Standard Error

+ The **standard error** gives you a sense of how different `\(\bar{x}\)` is likely to be from `\(\mu\)`

+ It helps you to evaluate how well your sample reflects the population

+ A smaller standard error suggests our estimate is likely to be closer to the true population parameter

--

`$$SE = \frac{\sigma}{\sqrt{N}}$$`


???

Why would we calculate this? Who has the time and resources to collect lots of different samples???

Don't worry, brilliant statisticians have figured out how you can estimate this value from a single sample.

---
## Calculation of Confidence Intervals

`$$95\%\  CI = \bar{x}\pm 1.96\times SE$$`

`\(\bar{x}\)`: sample mean

`\(SE\)`: the standard error

`\(\pm\)`: As this is an interval, both a lower and upper band must be calculated

---
## Calculation of Confidence Intervals

.pull-left[
+ Where does 1.96 come from when calculating the 95% CI?

+ When enough samples are taken, the sampling distribution approximates a **normal distribution**

  + Observations are symmetrically scattered on both sides of the mean
]

.pull-right[

![](Week02_DescribingEffects_lecture_files/figure-html/unnamed-chunk-15-1.svg)&lt;!-- --&gt;


]

---
count: false

## Calculation of Confidence Intervals

.pull-left[
+ Where does 1.96 come from when calculating the 95% CI?

+ When enough samples are taken, the sampling distribution approximates a **normal distribution**

  + Observations are symmetrically scattered on both sides of the mean
  + **95%** of observations in a normal distribution fall **1.96** standard errors from the mean
]

.pull-right[

![](Week02_DescribingEffects_lecture_files/figure-html/unnamed-chunk-16-1.svg)&lt;!-- --&gt;
]

---
## Calculation of Confidence Intervals

.pull-left[

`$$95\% \ CI = \bar{x}\pm 1.96\times SE$$`
]

.pull-right[
`$$SE = \frac{s}{\sqrt{n}}$$`
]

&gt; Test your Understanding: Imagine you have an attention assessment that you have tested in a sample of 525 university students. The mean score is 42.35 and the sd is 5.62.

--

&gt; What is n?

&gt; What is the SE?

&gt; What is the lower band of the 95% CI?

&gt; What is the upper band of the 95% CI?


---
## Calculation of Confidence Intervals

`$$SE = \frac{s}{\sqrt{n}}$$`

**Step 1:** Calculate the Standard Error

`\(SE = \frac{5.62}{\sqrt{525}}\)`

--

`\(SE = 0.25\)`


---
## Calculation of Confidence Intervals

`$$95\% \ CI = \bar{x}\pm 1.96\times SE$$`

.pull-left[

**Step 2:** Calculate the Lower Band of 95% CI

`\(95\% \ CI = 42.35 - 1.96\times 0.25\)`


`\(95\% \ CI = 42.35 - 0.49\)`


`\(95\% \ CI = 41.86\)`

]

--

.pull-right[
**Step 3:** Calculate the Higher Band of 95% CI


`\(95\% \ CI = 42.35 + 0.49\)`


`\(95\% \ CI = 42.84\)`

]

---
## Visualisation of Confidence Intervals

.pull-left[
![](Week02_DescribingEffects_lecture_files/figure-html/unnamed-chunk-17-1.svg)&lt;!-- --&gt;

]

--

.pull-right[

&gt; **Test Your Understanding:** If you were to instead plot the 99% CI, would the error bars be longer or shorter?

]


---
count: false

## Visualisation of Confidence Intervals

.pull-left[
![](Week02_DescribingEffects_lecture_files/figure-html/unnamed-chunk-18-1.svg)&lt;!-- --&gt;
]

.pull-right[

![](Week02_DescribingEffects_lecture_files/figure-html/unnamed-chunk-19-1.svg)&lt;!-- --&gt;
]

---
count: false
class: center, inverse, middle

## Questions?


---

## Power

+ Recall last week's discussion about Type I &amp; Type II error

+ The `\(\alpha\)` threshold reflects a study's risk of a Type I error

--

+ Similarly, we have to make a decision about how much we want to risk making a **Type II error** 

  + The probability of making a Type II error is known as `\(\beta\)`
  
+ An analysis's power reflects how likely it is that an effect will be detected *if it exists*
  
  + AKA, 1 - `\(\beta\)`

---

## Power
  
+ A conventional value for power is .8 (80% power)

+ This means there is a 20% chance of making a Type II error

+ When designing a study, a power analysis should be conducted to ensure that this power threshold will be reached given the sample constraints of the study

  + The type of power analysis you use will depend upon the statistical test you plan to perform

---
## Power

+ There are typically four numbers that go into a power analysis. If you have 3 of these numbers, you can solve for the fourth:

  + `\(\alpha\)`
  + Effect Size
  + `\(n\)`
  + Power

--

&gt; **Test Your Understanding:** How do you think each of these values affects your ability to detect an effect?

---
## Types of Power Analyses

+ In most a priori power analyses, you'll want to calculate the **sample** required to get 80% power for a specific effect size and `\(\alpha\)` value.

+ However, if you already have a set sample (e.g. a secondary data analysis), you might want to compute the **effect size** that it can detect, given certain `\(\alpha\)` and power thresholds.

+ In this course, we'll be using [WebPower](https://webpower.psychstat.org/wiki/models/index) to conduct power analysis.


---

## To summarise...

.center[
&lt;img src="images/ErrorTableAlphaBeta.png" width="75%" /&gt;
]

---
class: center, inverse, middle

## Questions?
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
