<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title> Confidence Intervals, Effect Sizes, and Power </title>
    <meta charset="utf-8" />
    <meta name="author" content="Monica Truelove-Hill" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# <b> Confidence Intervals, Effect Sizes, and Power </b>
]
.subtitle[
## Inferential Statistics in Applied Psychology<br>
]
.author[
### Monica Truelove-Hill
]
.institute[
### Department of Clinical Psychology<br>The University of Edinburgh
]

---








## This Week's Key Topics

---
---
## Effect Size

+ On it's own, a `\(p\)`-value is not sufficient. 

.pull-left[.center[

]]

.pull-right[.center[

]]

---
count: false

## Effect Size

+ On it's own, a `\(p\)`-value is not sufficient. 

.pull-left[.center[


** `\(p\)` = .015**
]]


.pull-right[.center[


** `\(p\)` = .015**
]]

---
## Effect Size

+ The **effect size** describes the magnitude of the effect or relationship

+ Unlike a `\(p\)`-value, which only tells you the likelihood that an effect or relationship exists, the effect size tells you how strong it is.

+ Different measures of effect size depending on your data/the statistical test you use

+ Usually standardised so that you can make comparisons across different variables

--

.pull-left.center[



]

.pull-right.center[



]


???

Think about practical significance - a pharmaceutical company tests the effect of their new vitamin and finds that it significantly decreases the amount of time someone is sick over the course of a year. SIGNIFICANCE! But wait...it only decreases the amount of sick days by a single day. EFFECT SIZE. Do they really want to spend an immense amount of money for a single day's improvement?

---
## Confidence Intervals

+ Remember, we don't actually know the population parameter; we're trying to estimate this with our data.

+ A **confidence interval** defines a plausible range of values for our population parameter. 

+ The wider the interval, the more confident that we can be that the interval captures our true value.

--

&gt; How many of you are confident that I'm exactly 35 years old?

--

&gt; How many of you are confident that I'm between 33 &amp; 38 years old?

--

&gt; How many of you are confident that I'm between 29 &amp; 42 years old?

--

&gt; How many of you are confident that I'm between 25 &amp; 46 years old?
  
---
## Confidence Level

+ To estimate the confidence interval, we need:

  + To define a confidence level
  + The standard error

+ The **confidence level** refers to the percentage of times confidence intervals would be expected to contain the true population parameter across repeated samples.

+ The typical confidence level used is **95%**, although you might also see 90% or 99%

+ So, if we were to take 100 samples and calculate a 95% CI on each of them, ~95 of those intervals would contain the true population parameter.


???

+ What are we 95% confident in?

  + We are 95% confident that our interval contains the true population mean.
  
  + The 95% probability comes from the long-run frequencies of our intervals.

---
## Standard Error

+ The average deviation from the mean *within* our sample is the **standard deviation**

+ Now imagine you took multiple samples and plotted their means:

--

.center[

]

---
count: false

## Standard Error

+ The average deviation from the mean *within* our sample is the **standard deviation**

+ Now imagine you took multiple samples and plotted their means:

.center[

]

---
count: false

## Standard Error

+ The average deviation from the mean *within* our sample is the **standard deviation**

+ Now imagine you took multiple samples and plotted their means:

.center[

]

---
count: false

## Standard Error

+ The average deviation from the mean *within* our sample is the **standard deviation**

+ Now imagine you took multiple samples and plotted their means:

.center[

]

---
count: false

## Standard Error

+ The average deviation from the mean *within* our sample is the **standard deviation**

+ Now imagine you took multiple samples and plotted their means:

.center[

]

---
count: false

## Standard Error

+ The average deviation from the mean *within* our sample is the **standard deviation**

+ Now imagine you took multiple samples and plotted their means:

.center[

]

--

+ The average deviation from the mean of the means *between* samples is the **standard error**

---
## Standard Error

+ The **standard error** gives you a sense of how different `\(\bar{x}\)` is likely to be from `\(\mu\)`

+ It helps you to evaluate how well your sample reflects the population

+ A smaller standard error suggests our estimate is likely to be closer to the true population parameter

--

`$$SE = \frac{\sigma}{\sqrt{N}}$$`


???

Why would we calculate this? Who has the time and resources to collect lots of different samples???

Don't worry, brilliant statisticians have figured out how you can estimate this value from a single sample.

---
## Calculation of Confidence Intervals

+ As this is an interval, you'll need to calculate both a lower and upper band.

--

`$$CI = \bar{x}\pm z\times SE$$`

`\(\bar{x}\)`: sample mean

`\(z\)`: `\(z\)`-score associated with the confidence level
  + 90% = 1.64
  + 95% = 1.96
  + 99% = 2.58

`\(SE\)`: the standard error

---
## Calculation of Confidence Intervals

.pull-left[

`$$95\% \ CI = \bar{x}\pm 1.96\times SE$$`
]

.pull-right[
`$$SE = \frac{s}{\sqrt{n}}$$`
]

&gt; Test your Understanding: Imagine you have an attention assessment that you have tested in a sample of 525 university students. The mean score is 42.35 and the sd is 5.62.

--

&gt; What is n?

&gt; What is the SE?

&gt; What is the lower band of the 95% CI?

&gt; What is the upper band of the 95% CI?


---
## Calculation of Confidence Intervals

`$$SE = \frac{s}{\sqrt{n}}$$`

**Step 1:** Calculate the Standard Error

`\(SE = \frac{5.62}{\sqrt{525}}\)`

--

`\(SE = 0.25\)`


---
## Calculation of Confidence Intervals

`$$95\% \ CI = \bar{x}\pm 1.96\times SE$$`

.pull-left[

**Step 2:** Calculate the Lower Band of 95% CI

`\(95\% \ CI = 42.35 - 1.96\times 0.25\)`


`\(95\% \ CI = 42.35 - 0.49\)`


`\(95\% \ CI = 41.86\)`

]

--

.pull-right[
**Step 3:** Calculate the Higher Band of 95% CI


`\(95\% \ CI = 42.35 + 0.49\)`


`\(95\% \ CI = 42.84\)`

]

---
## Visualisation of Confidence Intervals

.pull-left[


]

--

.pull-right[

&gt; **Test Your Understanding:** If you were to instead plot the 99% CI, would the error bars be longer or shorter?

]


---
count: false

## Visualisation of Confidence Intervals

.pull-left[

]

.pull-right[


]

---
count: false
class: center, inverse, middle

## Questions?

---
## Errors

+ Whether your decision is either to reject or not reject the null hypothesis, you may be making an error.

--

+ Two types of errors:

  + **Type I Error:** You reject a true null hypothesis (i.e., you believe a result is significant when it is not)
  
  + **Type II Error:** You don't reject a false null hypothesis (i.e., you don't think a result is significant when it is)


--

.center[

]

---

## `\(\alpha\)`

+ Rejecting the null when it is actually true is known as a **Type I error**. 

  + We have to make a decision about how much we want to risk making a Type I error

  + Our accepted risk threshold is known as `\(\alpha\)`
  
  + `\(\alpha\)` reflects the probability of making a Type I error

--
  
+ Typical `\(\alpha\)` value is .05, but may sometimes be set at .01 or .001.

--

+ If our `\(p\)`-value is equal to or less than our predetermined `\(\alpha\)`, we consider our results to be significant.

---

## `\(\alpha\)`

.pull-left[
.center[ ** `\(\alpha\)` = .05**



]
]

--

.pull-right[
.center[ ** `\(\alpha\)` = .01**



]
]
---

## Power

+ Similarly, we have to make a decision about how much we want to risk making a **Type II error** 

  + The probability of making a Type II error is known as `\(\beta\)`
  
+ An analysis's power is associated with the likelihood of making a Type II error.
  
  + It tells us how likely we are to detect an effect *if it exists*
  
  + AKA, 1 - `\(\beta\)`

--
  
+ A conventional value for power is .8 (80% power)

+ This means there is a 20% chance of making a Type II error


---

## Power

+ There are typically four numbers that go into a power calculation. If you have 3 of these numbers, you can solve for the fourth:

  + `\(\alpha\)`
  + Effect Size
  + `\(n\)`
  + Power

--

&gt; **Test Your Understanding:** How do you think each of these values affects your ability to detect an effect?

---
count: false

## Power

+ There are typically four numbers that go into a power calculation. If you have 3 of these numbers, you can solve for the fourth:

  + `\(\alpha\)`
  + Effect Size
  + `\(n\)`
  + Power

+ In most a priori power analyses, you'll want to check the sample required to get 80% power for a specific effect size.

+ However, if you already have a set sample, you might want to check the effect size that it has the power to detect.

---

## To summarise...

.center[

]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
